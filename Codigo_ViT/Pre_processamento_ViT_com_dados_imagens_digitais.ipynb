{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UPjELpQU3YU"
      },
      "source": [
        "### Passos necessários\n",
        "\n",
        "1. Ler as imagens digitais;\n",
        "2. Remover os background;\n",
        "3. criar os embeddings;\n",
        "4. Salvar os embeddings em um vector store ou refazer sempre que for executar;\n",
        "<!-- 3. Pegar áreas novas, criar embeddings e classificar\n",
        "4. Salva junto uma classe no vector store, e retorná-lo -->"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ambiente vit conda\n",
        "# conda create -n vit python==3.10\n",
        "# conda activate vit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EioIk52T0fdH",
        "outputId": "57340b69-e4b2-4fb2-809a-5580e48ac57e"
      },
      "outputs": [],
      "source": [
        "#!pip install faiss-gpu\n",
        "#!pip install faiss-cpu\n",
        "#!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "48ASC9BkSx0-"
      },
      "outputs": [],
      "source": [
        "# Lendo as bibliotecas\n",
        "from transformers import ViTImageProcessor, ViTModel\n",
        "from PIL import Image\n",
        "import os\n",
        "import torch\n",
        "\n",
        "from rembg import remove\n",
        "import io\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import faiss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pre-processar as imagens -\n",
        "# Padronizar as imagens e remover background\n",
        "\n",
        "def processar_imagens_otimizado(caminho_pasta_entrada, caminho_pasta_saida, largura=640, altura=480):\n",
        "    # (Mesma função processar_imagens_otimizado que você já tem)\n",
        "    if not os.path.exists(caminho_pasta_saida):\n",
        "        os.makedirs(caminho_pasta_saida)\n",
        "        print(f\"Pasta de saída criada: {caminho_pasta_saida}\")\n",
        "\n",
        "    lista_indices_caminhos = []\n",
        "    indice_atual = 0\n",
        "\n",
        "    for raiz, _, arquivos in os.walk(caminho_pasta_entrada):\n",
        "        arquivos.sort() # Garante uma ordem consistente\n",
        "        \n",
        "        for arquivo in arquivos:\n",
        "            if arquivo.lower().endswith(('.png', '.jpg', '.jpeg', '.webp', '.bmp', '.tiff')):\n",
        "                caminho_completo_entrada = os.path.join(raiz, arquivo)\n",
        "                \n",
        "                lista_indices_caminhos.append({\n",
        "                    'indice': indice_atual,\n",
        "                    'caminho_original': caminho_completo_entrada\n",
        "                })\n",
        "                indice_atual += 1\n",
        "\n",
        "                nome_arquivo_sem_ext, extensao = os.path.splitext(arquivo)\n",
        "                extensao_saida = '.png' if extensao.lower() != '.png' else extensao\n",
        "                nome_arquivo_saida = f\"{nome_arquivo_sem_ext}_processado{extensao_saida}\"\n",
        "                caminho_completo_saida = os.path.join(caminho_pasta_saida, nome_arquivo_saida)\n",
        "\n",
        "                try:\n",
        "                    img_original = Image.open(caminho_completo_entrada)\n",
        "                    img_redimensionada = img_original.resize((largura, altura), Image.LANCZOS)\n",
        "\n",
        "                    buffer_img = io.BytesIO()\n",
        "                    img_redimensionada.save(buffer_img, format='PNG' if extensao_saida == '.png' else img_original.format)\n",
        "                    buffer_img.seek(0)\n",
        "\n",
        "                    bytes_entrada = buffer_img.read()\n",
        "                    bytes_saida = remove(bytes_entrada)\n",
        "\n",
        "                    with open(caminho_completo_saida, 'wb') as o:\n",
        "                        o.write(bytes_saida)\n",
        "                    print(f\"Processado e salvo: {caminho_completo_saida} (Original: {caminho_completo_entrada})\")\n",
        "\n",
        "                except FileNotFoundError:\n",
        "                    print(f\"Erro: Arquivo não encontrado: {caminho_completo_entrada}\")\n",
        "                except Exception as e:\n",
        "                    print(f\"Erro ao processar {caminho_completo_entrada}: {e}\")\n",
        "\n",
        "    return lista_indices_caminhos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Exemplo de uso ---\n",
        "# Padronizar as imagens e remover background\n",
        "pasta_entrada = 'database/natural_images'\n",
        "pasta_saida = 'database/natural_images_without_bg'\n",
        "arquivo_csv_saida = 'database/indices_imagens_preprocessadas.csv' # ALtere este caminho\n",
        "\n",
        "# Processa as imagens e obtém a lista de índices/caminhos\n",
        "info_imagens = processar_imagens_otimizado(pasta_entrada, pasta_saida,largura=224, altura=224)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Salvando em CSV a lista de arquivos originais\n",
        "df = pd.DataFrame(info_imagens)\n",
        "df.to_csv(arquivo_csv_saida, index=False, encoding='utf-8') # index=False para não salvar o índice do DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ler as imagens da pasta database/natural_images_without_bg\n",
        "def ler_imagens(lista_imagens, raiz):\n",
        "    imagens = []\n",
        "\n",
        "    for arquivo in lista_imagens:\n",
        "        nome_arquivo = os.path.basename(arquivo)\n",
        "        nome_arquivo_sem_ext, extensao = os.path.splitext(nome_arquivo)\n",
        "        extensao_saida = '.png' if extensao.lower() != '.png' else extensao\n",
        "        nome_arquivo_saida = f\"{nome_arquivo_sem_ext}_processado{extensao_saida}\"\n",
        "        caminho_completo_saida = os.path.join(raiz, nome_arquivo_saida)\n",
        "\n",
        "        try:\n",
        "            img = Image.open(caminho_completo_saida)\n",
        "            img = img.convert('RGB')\n",
        "            imagens.append(img)\n",
        "            print(f\"Imagem lida: {caminho_completo_saida}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Não foi possível ler a imagem {caminho_completo_saida}: {e}\")\n",
        "    return imagens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Lendo as Imagens para criação dos Embeddings:\n",
        "lista = pd.read_csv(\"database/indices_imagens_preprocessadas.csv\")\n",
        "lista_imagens = lista[\"caminho_original\"]\n",
        "raiz = \"database/natural_images_without_bg/\"\n",
        "todas_as_imagens = ler_imagens(lista_imagens, raiz)\n",
        "print(f\"\\nTotal de imagens encontradas: {len(todas_as_imagens)}\")\n",
        "\n",
        "# Você pode acessar as imagens:\n",
        "# todas_as_imagens[0] # Mostra a primeira imagem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVfkA9fET9Eq"
      },
      "outputs": [],
      "source": [
        "# Lendo algoritmo ViT - PreTrained\n",
        "processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')\n",
        "model = ViTModel.from_pretrained('google/vit-base-patch16-224')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# O processor transforma as imagens para o formato que o modelo espera (pixels, normalização, etc.)\n",
        "# return_tensors=\"pt\" garante que a saída seja um tensor PyTorch.\n",
        "inputs = processor(images=todas_as_imagens[0], return_tensors=\"pt\")\n",
        "# 2. Passar as imagens pré-processadas pelo modelo ViT\n",
        "with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "# Pega o embedding\n",
        "cls_embedding = outputs.last_hidden_state[:, 0, :]  # shape: [1, 768]\n",
        "# Convertendo os logits para numpy (seu vetor de embeddings)\n",
        "img_embds = cls_embedding.numpy()\n",
        "# Normalize os embeddings (para usar distância do cosseno)\n",
        "img_embds = img_embds / np.linalg.norm(img_embds, axis=1, keepdims=True)\n",
        "# Definindo o índice FAISS para busca vetorial\n",
        "d = img_embds.shape[1]  # dimensão dos embeddings\n",
        "# Crie um índice para produto interno (proxy para distância do cosseno)\n",
        "index = faiss.IndexFlatIP(d)\n",
        "# Adicione os embeddings normalizados\n",
        "index.add(img_embds)\n",
        "print(f\"Número de itens no índice: {index.ntotal}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizano o vetor de embeddings\n",
        "img_embds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualizano o vetor de embeddings\n",
        "img_embds.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i in range(1,len(todas_as_imagens)):\n",
        "    # O processor transforma as imagens para o formato que o modelo espera (pixels, normalização, etc.)\n",
        "    # return_tensors=\"pt\" garante que a saída seja um tensor PyTorch.\n",
        "    inputs = processor(images=todas_as_imagens[i], return_tensors=\"pt\")\n",
        "    # 2. Passar as imagens pré-processadas pelo modelo ViT\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    # Pega o embedding\n",
        "    cls_embedding = outputs.last_hidden_state[:, 0, :]  # shape: [1, 768]\n",
        "    # Convertendo os logits para numpy (seu vetor de embeddings)\n",
        "    img_embds = cls_embedding.numpy()\n",
        "\n",
        "    # Normalize os embeddings (para usar distância do cosseno)\n",
        "    img_embds = img_embds / np.linalg.norm(img_embds, axis=1, keepdims=True)\n",
        "\n",
        "    # Adicione os embeddings normalizados\n",
        "    index.add(img_embds)\n",
        "    print(f\"Número de itens no índice: {index.ntotal}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "un5j6vLwEKeG"
      },
      "outputs": [],
      "source": [
        "# Suponha que 'index' seja seu índice FAISS\n",
        "faiss.write_index(index, 'faiss_index_embeddings/vector_databases_faiss_index.index')  # Salva o índice em um arquivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eL7MeQskDMwJ"
      },
      "outputs": [],
      "source": [
        "# Ler o índice do arquivo\n",
        "index = faiss.read_index('faiss_index_embeddings/vector_databases_faiss_index.index')  # Carrega o índice de um arquivo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuVWjG0_6TgJ",
        "outputId": "4ec8b2ec-7c4e-40e0-f54a-9e0fad30cfdc"
      },
      "outputs": [],
      "source": [
        "print(f\"Número de itens no índice: {index.ntotal}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
